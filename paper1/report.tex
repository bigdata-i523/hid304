\documentclass[letterpaper]{report}

\begin{document}
\title{Big Data and Astrophysics}
\maketitle

\section{Abstract}
How has Big Data been applied to existing Astrophysics and Astronomical datasets and how, if a all, has the insight gained from mining of this data altered the methods or technology used in the observational process.

\section{Introduction}
The volume of data generated by astrophysics and astronomical platforms rivals the output of other data sources. Astrophysics and astronomy are considered a primary domain generating 'Big Data', alongside Twitter, YouTube, and Genomics research. [18]. 

Astrophysics and astronomy data is generated by relatively few sources [18][22] but each of these sources generates data at a high volume, with high variety, and at high velocity[12]. The emergence of Big Data methods has changed the way astronomical data is gathered and has allowed for rapid growth in the scope and design of astronomical and astrophysical research[3]. 

\section{Big Data Challenges in Astrophysics}
Astronomic data requires perpetual development of data cleaning, storage, processing, searching, mining, and analysis tools. [3]. The data collection tools used for the most data-intensive sky surveys are primarily telescopes, which observe astronomical objects in high definition over a wide range of the electromagnetic spectrum from gamma rays, to visible light, to extremely-low frequency radio waves. [23]. The largest astronomic and astrophysics research projects have created databases of hundreds of terabytes, and projects in development are expected to capture data in the exabytes[13][21][22]. \\

The Large Synoptic Survey Telescope (LSST), the highest volume astronomical data project currently under construction, is expected to generate 15TB of data per day with over 200 dimensions of data per astronomical object [25]. This 3.2 gigapixel telescope camera is located in Cerro Pach√≥n,Chile and is expected to generate 30 terabytes of data each night of operation for a total of 150 petabytes over the predicted 10-year operational window [24]. \\

The highest-volume astronomical data project currently in the planning stages is the Square Kilometer Array (SKA), which is set to be constructed with portions of the array located in South Africa, Australia, and New Zealand; construction is expected to be completed in 2024. The data collection would consist of multiple radio telescopes in an array design spread over thousands of kilometers. This project would gather 14 exabytes of data each day of operation and store about 1 petabyte of that daily data[10]. Transmission of this data would match the entire data output of the internet in 2013[1]. \\

Making use of this data has challenged almost every part of the Big Data field. In the most basic sense, the processing of data from astronomical and astrophysics platforms is a process of recording high-definition images of the sky, comparing all parts of this image to preceding and successive images to determine the movement of individual objects, then directing the most likely candidates for real astronomical changes to human experts for classification [big data revolution in astrophysics]. The depth and detail of images varies depending on the project goals and wavelength of light being observed. 

For ground-based observation projects, the most common source of noise in data which requires cleaning are satellites, 'junk' in earth orbit, and defects in the telescope lens which can create artifacts[20]. Two of the most effective methods of cleaning astronomical datasets are the Hough Transform method and the Renewal String Approach[2][19][20]. Data curation and storage must be handled in a decentralized way, with researchers and space agencies across the globe contributing to archiving this flow of data to different cloud storage and open source storage systems[9][17]. The mining of astronomical data has created an entirely new field of 'Astroinformatics[4]' which focuses on efficient management of computing resources. Data mining of astrophysical and astronomical data requires search and selection features which can quickly return data relevant to a researcher's needs[11][16]. Different query solutions, including SQL, Map-Reduce tools, XtreemFS, and new tools constantly in development[7][15]. The ability to analyze astronomical data is ultimately a problem of identifying significant events, new attributes for astronomical objects, and interesting "front-page-news" outliers through the "petascale"[5] data containing high levels of noise as well as less significant data.
 
\section{How Big Data has Changed Astrophysics}
Astronomical and astrophysical data is growing rapidly in size, and researchers are able to gather increasingly large volumes of data as Big Data tool develop alongside the observational technology. 


Many of the leading Big Data tools in Astrophysics and Astronomy were developed around the Sloan Digital Sky Survey (SDSS)[6]. SDSS began observations in 1998 and gathered astronomical data as images until 2009. SDSS ultimately gathered 140 terabytes of data which quickly dwarfed the amount of data gathered in the entire history of astronomy. The fields of Astroinformatics and Astrostatistics emerged as data science caught up to this flow of data. The machine learning, data processing, data storage, and data querying were developed concurrent to SDSS and smaller sky surveys like the Palomar Digital Sky Survey, and the SkyMapper Southern Sky Survey[6][8][14]. 

The LSST and SKA are examples of research platforms designed with Big Data tools and methods in mind following the development of these tools with prior surveys. There is little indication that Astrophysics and Astronomy will become less data intensive in the future.  


\end{document}